{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "# The format string should match the format of the date and time string\n",
    "# In this case, the date and time string is in the format 'MM/DD/YY, HH:MM:SS AM/PM'\n",
    "date_time_format = '%m/%d/%y, %I:%M:%S %p'\n",
    "date_time_list = []\n",
    "name_list = []\n",
    "text_list = []\n",
    "total_file = []\n",
    "\n",
    "file = r\"C:\\Users\\markkw\\Downloads\\WhatsApp Chat\\_chat.txt\"\n",
    "with open(file, encoding=\"utf8\") as f:\n",
    "    for line in f.readlines():\n",
    "        total_file.append(line)\n",
    "        if line[0] == \"[\":\n",
    "            date_time_list.append(datetime.strptime(line.split(']', 1)[0].replace('[', ''), date_time_format))\n",
    "            name_list.append(line.split(']', 1)[1].split(\":\",1)[0])\n",
    "            if \":\" in line.split(']', 1)[1]:\n",
    "                text_list.append(line.split(']', 1)[1].split(\":\",1)[1].replace(\"\\n\", \"\"))\n",
    "            else: \n",
    "                text_list.append(\"-\")\n",
    "\n",
    "df = pd.DataFrame(index=[date_time_list])\n",
    "df['Person'] = name_list\n",
    "df['Message'] = text_list\n",
    "df = df[df['Message'] != \"-\"]\n",
    "pattern = re.compile(r\"|\".join(map(re.escape, emoji.EMOJI_DATA)))\n",
    "\n",
    "df[\"Emojis\"] = df[\"Message\"].apply(lambda x: \"\".join(pattern.findall(x)))\n",
    "df[\"Sentence\"] = df[\"Message\"].apply(lambda x: pattern.sub(\"\", x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import translators.server as tss\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_analyzer(text):\n",
    "    from_language, to_language = 'nl', 'en'\n",
    "    try:\n",
    "        translated_text = tss.google(text['Sentence'], from_language, to_language) + text['Emojis']\n",
    "    except:\n",
    "        translated_text = text['Sentence']\n",
    "    score = analyser.polarity_scores(translated_text)\n",
    "    \n",
    "    return score['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df.iloc[:200,:]\n",
    "df_test['Sentiment'] = df_test.apply(lambda row : sentiment_analyzer(row), axis=1)\n",
    "df['Emojis'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
